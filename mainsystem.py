# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'systemain.ui'
#
# Created by: PyQt5 UI code generator 5.15.1
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


#import test_rc
import sys
import cv2
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtGui import QImage, QPixmap
from PyQt5.QtWidgets import*
from PyQt5.QtCore import *
import copy
import math
import random
import numpy as np
from PIL import Image
from numpy import linalg as LA
import matplotlib.pyplot as plt
from scipy import ndimage as ndi
from sklearn.cluster import KMeans
from skimage import morphology,feature
from colormath.color_objects import LabColor
from colormath.color_diff import delta_e_cie2000
import time
import os




def gamma_correction(image, gamma):
    gamma_table = [np.power(x/255.0, gamma)*255 for x in range(256)]#直方圖等話，正規畫轉乘0~255之間，找灰階職
    gamma_table = np.round(np.array(gamma_table)).astype(np.uint8)#轉乘array
    return cv2.LUT(image, gamma_table)


def maxigap(list,unique):
    tem = []
    gap = []
    gap1 = []
    if len(list) < 2:
        return 0
    for t in range(1,len(list)):
        min_gap = int(list[t] - list[t-1])
        gap += [min_gap]
    print(gap)
    min_gap = min(gap)
    max_gap = max(gap)
    gap1 = gap.copy()
    max_gap1 = max(gap1)
    gap1.remove(max_gap1)
    sec_gap = max(gap1)
    print(sec_gap)
    for i in range(1,len(list)):
        temp = int(list[i]-list[i-1])
        #print(temp)
        if temp == max_gap or temp == sec_gap and temp > min_gap  :
            tem += [list[i]]
            tem += [list[i-1]]
    #print('原始',tem)
    tem = np.unique(tem).tolist()
    #print('刪除重複',tem)
    gap_num = (tem[2]- tem [1])/3
    new_d1 = int(tem[0] + gap_num*2)
    new_d2 = int(tem[2] - gap_num*2)
    out_num = tem[1]
    list.remove(out_num)
    del tem[1]
    tem.append(new_d1)
    tem.append(new_d2)
    #print(tem)
    new_list = np.concatenate([tem,list])
    for newlist in new_list:
        if newlist not in unique:
            unique.append(newlist)
            unique.sort()
    return unique


def hsv_w_turn(image,image_b):
    image = image.copy()
    img = image_b.copy()
    # img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    cv2.imwrite("./lcc_pic/kmeans/hsv.jpg",img)
    lower_w = np.array([192,192,192])
    upper_w = np.array([255,255,255])
    mask = cv2.inRange(img,lower_w,upper_w)#留下白色的部分
    cv2.imwrite("./lcc_pic/kmeans/mask.jpg", mask)
    kernel_1 = cv2.getStructuringElement(cv2.MORPH_RECT, (65,65))
    dilate = cv2.dilate(mask, kernel_1, iterations = 3)
    cv2.imwrite("./lcc_pic/kmeans/dilation.jpg",dilate)
    dilation = cv2.imread("./lcc_pic/kmeans/dilation.jpg")
    #修改
    kernel = np.ones((81,81), np.uint8)
    erode = cv2.erode(dilation, kernel , iterations = 3)
    cv2.imwrite("./lcc_pic/kmeans/erosion.jpg",erode)
    result = cv2.bitwise_and(image, erode)
    cv2.imwrite("./lcc_pic/kmeans/result_p.jpg",result)
    # result_p_mask = cv2.bitwise_not(mask)#把非白色部分遮掉
    # kernel_e = np.ones((5,5), np.uint8)
    # erosion = cv2.erode(result_p_mask, kernel_e , iterations = 3)
    # erosion = cv2.cvtColor(erosion, cv2.COLOR_GRAY2BGR)
    # cv2.imwrite("./lcc_pic/kmeans/result_p_mask.jpg", erosion)#留下拜色部分被遮掉很多的葉色塊mask
    # result_m = cv2.bitwise_and(result, erosion)
    # cv2.imwrite("./lcc_pic/kmeans/result.jpg", result_m)#葉色塊
    return result, erode#留下一般的mask跟一般的result

def keep_g(image):
    img_p = Image.open('./lcc_pic/kmeans/clone.jpg')
    #img_p = np.array(np.rot90(img_p,-1))
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    cv2.imwrite("./lcc_pic/kmeans/result_p_hsv.jpg", hsv)
    mask = cv2.inRange(hsv, (25, 43, 46), (102, 255, 255))
    imask = mask > 0
    cv2.imwrite("./lcc_pic/kmeans/result_p_mask.jpg", mask)
    mask = cv2.imread('./lcc_pic/kmeans/result_p_mask.jpg')
    k_size = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
    mask = cv2.dilate(mask, k_size, iterations = 3)
    k_size2 = np.ones((11,11), np.uint8)
    mask = cv2.erode(mask, k_size2 , iterations = 3)
    cv2.imwrite("./lcc_pic/kmeans/result_p_mask.jpg",mask)
    edged = cv2.Canny(mask, 35, 100)
    cv2.imwrite('./lcc_pic/kmeans/canny_mask.jpg',edged)
    (contours, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    clone = image.copy()
    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:7]
    if len(contours) == 7 and cv2.contourArea(contours[0])/cv2.contourArea(contours[1])>= 1.5 :
        contours.remove(contours[-1])
    seg_bgr = []
    seg_num = []
    l_list = []
    index_list =[]
    #葉色板取得大小調整
    cx_list = []
    cy_list = []
    for index, c in enumerate (contours):
        # print(index)
        M = cv2.moments(c)
        #取得每個輪廓的中心點
        print(M['m00'])
        x, y, w, h = cv2.boundingRect(c)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
        else:
    # set values as what you need in the situation
            cx, cy = 0, 0
        #新增的部分
        area = cv2.contourArea(c)
        cx_list += [cx]
        cy_list += [cy]
        new_y = int(sum(cy_list)/len(contours))
    w = 11
    if len(contours) == 7:
        #point_lcc = list(zip(cx_list, cy_list))
        for ind7 in range (len(contours)):
            index_list += [ind7]
        for inde, nx, ny in zip(index_list, cx_list, cy_list):
            lcc_c = img_p.crop((nx-w,ny-w,nx+w,ny+w))   
            lcc_c.save('./lcc_pic/kmeans/lcc_crop/crop_{num}.jpg'.format(num = inde))
            # img = cv2.imread('./lcc_crop/crop_{num}.jpg'.format(num = inde))
            seg_bgr.append(count_bgr(lcc_c))#存第i個葉色塊平均
            seg_num.append(inde)#存地i個葉色塊編碼
            l_list.append(nx-w)#存地i個葉色塊左邊位置
    elif len(contours) == 6 :
        cx_list.sort()
        print(cx_list)
        new_x = []
        maxigap(cx_list,new_x)
        cy_list.append(new_y)
        print(new_x,cy_list)
        for ind6 in range (len(contours)):
            index_list += [ind6]
        index_list.append(6)
        for inde, nx, ny in zip(index_list, new_x, cy_list):
            lcc_c = img_p.crop((nx-w,ny-w,nx+w,ny+w))   
            lcc_c.save('./lcc_pic/kmeans/lcc_crop/crop_{num}.jpg'.format(num = inde))
            # img = cv2.imread('./lcc_crop/crop_{num}.jpg'.format(num = inde))
            seg_bgr.append(count_bgr(lcc_c))#存第i個葉色塊平均
            seg_num.append(inde)#存地i個葉色塊編碼
            l_list.append(nx-w)#存地i個葉色塊左邊位置
    else :
        print('重新拍照')

    for m in range(len(l_list)):
        for n in range(len(l_list) - 1):
            if l_list[n] > l_list[n+1]:
                seg_bgr[n], seg_bgr[n+1] = seg_bgr[n+1], seg_bgr[n]
                seg_num[n], seg_num[n+1] = seg_num[n+1], seg_num[n]
                l_list[n], l_list[n+1] = l_list[n+1], l_list[n]
    # print("顏色深到淺編號：:", seg_num)
    # print(type(seg_bgr), type(seg_num))
    return seg_bgr, seg_num#色塊由深到淺的顏色、照片編號
    # green = np.zeros_like(result_p, np.uint8)
    # # cv2.imwrite("./lcc_pic/hsv/green.jpg", green)
    # green[imask] = result_p[imask] 
    # # print(green[imask])
    # cv2.imwrite("./lcc_pic/kmeans/result_p_green.jpg", green)
    # return green

def crop(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]
    hh, ww = thresh.shape
    thresh[hh-3:hh, 0:ww] = 0
    white = np.where(thresh==255)
    xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])
    # print(xmin,xmax,ymin,ymax)
    crop = img[ymin:ymax+3, xmin:xmax]
    cv2.imwrite('./lcc_pic/kmeans/thresh.jpg', thresh)
    cv2.imwrite('./lcc_pic/kmeans/crop.jpg', crop)
    return(crop)

def segment(img):
    # print(img)
    segmentator = cv2.ximgproc.segmentation.createGraphSegmentation(sigma = 0.5, k = 300,min_size=1000)
    segment = segmentator.processImage(img)
    cv2.imwrite('./lcc_pic/kmeans/seg.jpg',segment)
    mask = segment.reshape(list(segment.shape) + [1]).repeat(3,axis = 2)
    masked = np.ma.masked_array(img, fill_value=0)
    seg_bgr = []
    seg_num = []
    l_list = []
    for i in range(np.max(segment)):
        #masked.mask = mask != i 
        y, x = np.where(segment == i)
        color = [random.randint(0, 255), random.randint(0, 255),random.randint(0, 255)]
        top, bottom, left, right = min(y), max(y), min(x), max(x)
        dst = masked.filled()[top : bottom + 1 , left: right + 1 ]
        cv2.imwrite('./lcc_pic/kmeans/seg/segment_{num}.jpg'.format(num = i), dst)
        # img = cv2.imread('./lcc_pic/kmeans/seg/segment_{num}.jpg'.format(num = i))
        #print(img.shape,img.shape[0]/img.shape[1],img.shape[0]*img.shape[1])

        if 9700 <= dst.shape[0]*dst.shape[1] <= 17000 and 1.5 <= dst.shape[0]/dst.shape[1] <= 2.5 :
            seg_bgr.append(count_bgr(dst))#存第i個葉色塊平均
            seg_num.append(i)#存地i個葉色塊編碼
            l_list.append(left)#存地i個葉色塊左邊位置
        else:
            continue
            # print('It is not the main picture.')
    # print(l_list)
    # print(seg_num)
    for m in range(len(l_list) - 2):
        for n in range(len(l_list) - 1):
            if l_list[n] > l_list[n+1]:
                seg_bgr[n], seg_bgr[n+1] = seg_bgr[n+1], seg_bgr[n]
                seg_num[n], seg_num[n+1] = seg_num[n+1], seg_num[n]
                l_list[n], l_list[n+1] = l_list[n+1], l_list[n]
    #print("顏色深到淺編號：:", seg_num)
    return seg_bgr, seg_num

def count_bgr(image):
    r_count = 0
    g_count = 0
    b_count = 0
    bgr = []
    count = 0
    image = image.convert('RGB')
    width = image.size[0]
    height = image.size[1]
    # print(image.size[0])
    for x in range(width):
        for y in range(height):
            # bgr_array += image[x, y]
            r, g, b = image.getpixel((x, y))
            r_count += r
            g_count += g
            b_count += b
            # if np.array_equal(image[x, y], [0, 0, 0]) != True:
            if(r != 0 and g != 0 and b != 0):
                count += 1

    # print(bgr_array)
    # print(count)
    bgr.append(b_count/count)#b
    bgr.append(g_count/count)#g
    bgr.append(r_count/count)#r
    print(bgr)
    return(bgr)
    # print(bgr_array[0]/count, '', bgr_array[1]/count, '', bgr_array[2]/count) 


def find_grass(image, image_b, mask):
    image = image.copy()
    img = image_b.copy()
    mask = mask.copy()
    opposite_mask = cv2.bitwise_not(mask)
    kernel = np.ones((9,9), np.uint8)
    opposite_mask = cv2.erode(opposite_mask, kernel, iterations = 3)
    # opposite_mask = cv2.cvtColor(opposite_mask, cv2.COLOR_GRAY2BGR)
    cv2.imwrite("./lcc_pic/kmeans/opposite_mask.jpg",opposite_mask)
    plates_mask = cv2.bitwise_and(image, opposite_mask)
    cv2.imwrite("./lcc_pic/kmeans/plates_mask.jpg",plates_mask)
    hsv = cv2.cvtColor(plates_mask, cv2.COLOR_BGR2HSV)
    grass_mask = cv2.inRange(hsv, (25, 43, 46), (102, 255, 255))
    imask = grass_mask > 0
    grass = np.zeros_like(plates_mask, np.uint8)
    grass[imask] = plates_mask[imask]
    cv2.imwrite("./lcc_pic/kmeans/grass.jpg", grass)
    return grass, grass_mask

def rmbg(img):
    sum_img = np.sum(img, axis = 2)
    mask_img = img[sum_img > 0].reshape(-1, 3)
    kmeans = KMeans(n_clusters = 3, init = 'random', n_init = 1000, random_state = 0).fit(mask_img)
    bgr_centers = kmeans.cluster_centers_
    # rgb_dists = LA.norm(rgb_centers, ord = 2, axis = 1)
    # sec_center = rgb_centers[np.argsort(rgb_dists)[1]]
    y = []
    for i in range(len(bgr_centers)):
        # print(bgr_centers[i])
        y.append(.299*bgr_centers[i][0] + .587*bgr_centers[i][1] + .114*bgr_centers[i][2])
    # print(y)

    for m in range(len(y)):
        for n in range(len(y) - 1):
            if y[n] > y[n+1]:
                y[n], y[n+1] = y[n+1], y[n] 
                bgr_centers[n], bgr_centers[n+1] = bgr_centers[n+1], bgr_centers[n]
    # print("葉子顏色中心：", bgr_centers[1])
    return bgr_centers[1]
    # print(y[1])
    # return y[1]

def ColourDistance(bgr_1, bgr_2):
    # print("bgr_1",bgr_1)
    B_1,G_1,R_1 = bgr_1
    # print(B_1,G_1,R_1)
    B_2,G_2,R_2 = bgr_2
    rmean = (R_1 +R_2 ) / 2
    R = R_1 - R_2
    G = G_1 -G_2
    B = B_1 - B_2
    return math.sqrt((2+rmean/256)*(R**2)+4*(G**2)+(2+(255-rmean)/256)*(B**2))

def HSVDistance(hsv1,hsv2):
    # print(hsv1)
    hsv_1 = np.uint8([[[hsv1[0],hsv1[1],hsv1[2]]]])
    hsv_2 = np.uint8([[[hsv2[0],hsv2[1],hsv2[2]]]])
    hsv_1 = cv2.cvtColor(hsv_1, cv2.COLOR_BGR2HSV)
    # print(hsv_1)
    hsv_2 = cv2.cvtColor(hsv_2, cv2.COLOR_BGR2HSV)
    H_1,S_1,V_1 = hsv_1[0][0][0],hsv_1[0][0][1],hsv_1[0][0][2]
    H_2,S_2,V_2 = hsv_2[0][0][0],hsv_2[0][0][1],hsv_2[0][0][2]
    R=100
    angle=30
    h = R * math.cos(angle / 180 * math.pi)
    r = R * math.sin(angle / 180 * math.pi)
    x1 = r * V_1 * S_1 * math.cos(H_1 / 180 * math.pi);
    y1 = r * V_1 * S_1 * math.sin(H_1 / 180 * math.pi);
    z1 = h * (1 - V_1);
    x2 = r * V_2 * S_1 * math.cos(H_2 / 180 * math.pi);
    y2 = r * V_2 * S_1 * math.sin(H_2 / 180 * math.pi);
    z2 = h * (1 - V_2);
    dx = x1 - x2;
    dy = y1 - y2;
    dz = z1 - z2;
    return math.sqrt(dx * dx + dy * dy + dz * dz);

def cie2000(bgr1, bgr2):
    bgr_1 = np.uint8([[[bgr1[0],bgr1[1],bgr1[2]]]])
    bgr_2 = np.uint8([[[bgr2[0],bgr2[1],bgr2[2]]]])
    bgr_1 = cv2.cvtColor(bgr_1, cv2.COLOR_BGR2Lab)
    bgr_2 = cv2.cvtColor(bgr_2, cv2.COLOR_BGR2Lab)
    color1_lab = LabColor(lab_l=bgr_1[0][0][0], lab_a=bgr_1[0][0][1], lab_b=bgr_1[0][0][2])
    color2_lab = LabColor(lab_l=bgr_2[0][0][0], lab_a=bgr_2[0][0][1], lab_b=bgr_2[0][0][2])
    diff = delta_e_cie2000(color1_lab, color2_lab)
    return diff








#主程式介面
class Ui_MainWindow(QtWidgets.QMainWindow):
    def __init__(self):
        super(Ui_MainWindow,self).__init__()
        self.setupUi(self)
        self.retranslateUi(self)

    def newindow(self):
        self.Ui_MainWindow2 = MainWindow2(self)
        self.Ui_MainWindow2.closed.connect(self.show)
        self.mainwindow2.show()
        self.hide()

    def setupUi(self, MainWindow):
        MainWindow.setObjectName("MainWindow")
        MainWindow.setFixedSize(508, 475)
        self.centralwidget = QtWidgets.QWidget(MainWindow)
        self.centralwidget.setObjectName("centralwidget")
        self.label = QtWidgets.QLabel(self.centralwidget)
        self.label.setGeometry(QtCore.QRect(-30, -10, 571, 501))
        self.label.setStyleSheet("background-image: url(./background1.png);")
        self.label.setObjectName("label")
        self.pushButton = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton.setGeometry(QtCore.QRect(190, 240, 131, 31))
        self.pushButton.setObjectName("pushButton")
        self.pushButton_2 = QtWidgets.QPushButton(self.centralwidget)
        self.pushButton_2.setGeometry(QtCore.QRect(190, 290, 131, 31))
        self.pushButton_2.setObjectName("pushButton_2")
        MainWindow.setCentralWidget(self.centralwidget)
        self.menubar = QtWidgets.QMenuBar(MainWindow)
        self.menubar.setGeometry(QtCore.QRect(0, 0, 508, 22))
        self.menubar.setObjectName("menubar")
        MainWindow.setMenuBar(self.menubar)
        self.statusbar = QtWidgets.QStatusBar(MainWindow)
        self.statusbar.setObjectName("statusbar")
        MainWindow.setStatusBar(self.statusbar)
        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)


    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "歡迎進入稻葉葉色辨識系統"))
        self.label.setToolTip(_translate("MainWindow", "<html><head/><body><p><img src=\":/newPrefix/background1.png\"/></p></body></html>"))
        self.label.setWhatsThis(_translate("MainWindow", "<html><head/><body><p><img src=\":/newPrefix/background1.png\"/></p></body></html>"))
        self.label.setText(_translate("MainWindow", "Tex"))
        self.pushButton.setText(_translate("MainWindow", "一般模式"))
        self.pushButton_2.setText(_translate("MainWindow", "分解模式"))


#第一個子視窗
class ImageLabel(QLabel):
    scale = 1.0
    def showImage(self, img):
        height, width, channel = img.shape
        bytesPerline = 3 * width
        self.qImg = QImage(img.data, width, height, bytesPerline, QImage.Format_RGB888).rgbSwapped()
        self.setPixmap(QPixmap.fromImage(self.qImg))

    def mousePressEvent(self,event):
        self.x = event.x()
        self.y = event.y()

    def mouseMoveEvent(self, event):
        self.x = event.x()
        self.y = event.y()

    def wheelEvent(self, event):
        numDegrees = event.angleDelta() / 8
        numSteps = numDegrees / 15       
        #print(numSteps.y())
        height, width, _ = self.img.shape
        if numSteps.y() == -1:
            if (self.scale >= 0.1):
                self.scale -= 0.05
        else:
            if (self.scale <= 2.0):
                self.scale += 0.05
        #print(self.scale)
        height2 = int(height * self.scale)
        width2 = int(width * self.scale)
        img2 = cv2.resize(self.img, (width2, height2), interpolation=cv2.INTER_AREA)
        self.showImage(img2)

class MyDialog(QDialog):
    def __init__(self):
        super().__init__()
        title = "稻葉葉色辨識系統"
        self.setWindowTitle(title)
        self.initUI()

    def show_cam(self):
        new_window = Ui_MainWindow(self)
        new_window.show()
        new_window.exec()

    def initUI(self):
        self.label = ImageLabel()
        self.setFixedSize(940, 730)
        self.label.setScaledContents(True)
        #self.label.setMouseTracking(True)
        self.btnOpen = QPushButton('選取影像', self)
        self.btnProcess = QPushButton('葉色分析', self)
        #self.btnProcess.setEnabled(False)
        self.btnCam = QPushButton('相機拍攝', self)
        self.btnany = QPushButton('使用說明', self)
        #self.label1 = QLabel('各葉色塊 X 點辨識：',self)
        #self.label0 = QLabel('最接近的葉色塊號：',self)
        self.label1 = QLabel('  最接近的葉色色塊號：',self)
        #self.btnSave.clicked.connect(self.show_cam)
        #self.label2 = QLabel('建議給予稻葉：',self)
        layout = QGridLayout(self)
        layout.addWidget(self.label, 0, 0, 4, 4)
        layout.addWidget(self.btnOpen, 5, 1, 1, 1)
        layout.addWidget(self.btnCam, 5, 2, 1, 1)
        layout.addWidget(self.btnProcess, 5, 3, 1, 1)
        #layout.addWidget(self.label, 1,3,1,1)
        layout.addWidget(self.btnany, 5,0,1,1)
        #layout.addWidget(self.label0, 4,1,1,1)
        layout.addWidget(self.label1, 4,3,1,1)
        #layout.addWidget(self.label2, 4,3,1,1)

        self.btnOpen.clicked.connect(self.openSlot)
        self.btnProcess.clicked.connect(self.processSlot)
        self.btnCam.clicked.connect(self.camSlot)
        self.btnany.clicked.connect(self.inforSlot)

    def camSlot(self):
        os.system("python subcam.py")


    def closeEvent(self, event):
        reply = QMessageBox.question(self, '詢問', '請問是否確定返回首頁？',QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
        if reply == QMessageBox.Yes:
            event.accept()
        else:
            event.ignore()

    def openSlot(self):
        self.resize(900,600)
        filename, _ = QFileDialog.getOpenFileName(self, '選取影像', 'Image', '*.png *.jpg *.bmp')
        if filename is '':
            return
        self.label.img = cv2.imread(filename, -1)
        if self.label.img.size == 1:
            return
        self.label.img = cv2.resize(self.label.img,(900,600))
        self.label.showImage(self.label.img)
        height, width, _ = self.label.img.shape
        self.label.setFixedSize(width, height)
        self.btnSave.setEnabled(True)



    def saveSlot(self):
        filename, _ = QFileDialog.getSaveFileName(self, '影像分析', 'Image', '*.png *.jpg *.bmp')
        self.label.showImage(self.label.img)
        height, width, _ = self.label.img.shape
        self.label.setFixedSize(width, height)
        if filename is '':
            return

    def processSlot(self):
        cv2.imwrite('./lcc_pic/kmeans/clone.jpg',self.label.img)
        img_s = self.label.img.copy()
        b, g, r = cv2.split(img_s)
        y = .299*r + .587*g + .114*b
        u = -.14713*r -.28886*g + .436*b
        v = .615*r -.51499*g -.10001*b
        y_max = np.max(y)
        y_min = np.min(y)

        y =(((y - y_min)/(y_max - y_min))*255)
        cv2.imwrite('./lcc_pic/kmeans/y.jpg',y)
        image = cv2.imread('./lcc_pic/kmeans/y.jpg')
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        mean = np.mean(gray)
        gamma_val = math.log10(1/2)/math.log10(mean/255)
        img_gammac = gamma_correction(image, gamma_val)
        cv2.imwrite('./lcc_pic/kmeans/gamma_c.jpg',img_gammac)
        k_size = 25
        blur = cv2.GaussianBlur(img_gammac,(k_size,k_size),0)
        cv2.imwrite('./lcc_pic/kmeans/blur.jpg',blur)
        result_p, mask = hsv_w_turn(img_s,blur)
        seg_bgr, seg_num = keep_g(result_p)
        seg_bgr1 = list(reversed(seg_bgr))
        seg_num1 = list(reversed(seg_num))
        #print("顏色淺到深編號：:", seg_num1)
        seg_num2 = seg_num1.copy()

        kernel_1 = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))
        dilate = cv2.dilate(mask, kernel_1, iterations = 3)
        grass, gmask = find_grass(img_s, blur, dilate)
        cv2.imwrite('./lcc_pic/kmeans/gmask.jpg',gmask)
        bgr_center = rmbg(grass)

        dist = []
        for i in range(len(seg_bgr1)):
            dist.append(ColourDistance(seg_bgr1[i], bgr_center))

        for m in range(len(dist)):
            for n in range(len(dist) - 1):
                if dist[n] > dist[n+1]:
                    dist[n], dist[n+1] = dist[n+1], dist[n]
                    seg_num1[n], seg_num1[n+1] = seg_num1[n+1], seg_num1[n]

        #print("距離排序編號",seg_num1)
        corr0_num = int(seg_num2.index(seg_num1[0]))
        print(corr0_num)
        corr_num = str(corr0_num + 1)
        self.label1.setText("  最接近的葉色色塊號："+corr_num+" 號")


    def inforSlot(self):
        QMessageBox.information(self, '使用說明','本系統提供使用者將含稻葉與葉色板之照片進行顏色比對，一次將照片中所有稻葉顏色進行葉色分析得出結果。',QMessageBox.Yes|QMessageBox.No,QMessageBox.Yes) 




#分解模式

class MyDialog2(QDialog):
    def __init__(self):
        super().__init__()
        title = "稻葉葉色辨識系統"
        self.setWindowTitle(title)
        self.initUI()

    def initUI(self):
        self.label = ImageLabel()
        self.setFixedSize(940, 750)
        self.label.setScaledContents(True)
        self.btnOpen = QPushButton('選取影像', self)
        self.btnany = QPushButton('使用說明', self)
        self.btnblur = QPushButton('高斯模糊', self)
        self.btnanyblur = QPushButton('使用說明', self)
        self.btngamma = QPushButton('伽瑪校正', self)
        self.btnanygamma = QPushButton('使用說明', self)
        self.btnlcc = QPushButton('取葉色板', self)
        self.btnanylcc = QPushButton('使用說明', self)
        self.btngrass = QPushButton('取下稻葉', self)
        self.btnanygrass = QPushButton('使用說明', self)
        self.btnProcess = QPushButton('葉色分析', self)
        self.btnanyprocess = QPushButton('使用說明', self)
        self.btnSave = QPushButton('儲存影像', self)
        self.label1 = QLabel('最接近色塊：',self)

        layout = QGridLayout(self)
        layout.addWidget(self.btnOpen, 5, 0, 1, 1)
        layout.addWidget(self.btnany, 6,0,1,1)
        layout.addWidget(self.btnblur, 5, 3, 1, 1)
        layout.addWidget(self.btnanyblur, 6,3,1,1)
        layout.addWidget(self.btngamma, 5,2,1,1)
        layout.addWidget(self.btnanygamma, 6,2,1,1)
        layout.addWidget(self.btnlcc, 5,4,1,1)
        layout.addWidget(self.btnanylcc, 6,4,1,1)
        layout.addWidget(self.btngrass, 5,5,1,1)
        layout.addWidget(self.btnanygrass, 6,5,1,1)
        layout.addWidget(self.btnProcess, 5, 1, 1, 1)
        layout.addWidget(self.btnanyprocess, 6, 1, 1, 1)
        layout.addWidget(self.btnSave, 5, 7, 1, 1)
        layout.addWidget(self.label1, 4,5,1,1)
        layout.addWidget(self.label, 0, 0, 4, 4)

        self.btnOpen.clicked.connect(self.openSlot)
        self.btngamma.clicked.connect(self.gammaSlot)
        self.btnblur.clicked.connect(self.blurSlot)
        self.btnProcess.clicked.connect(self.processSlot)
        self.btnSave.clicked.connect(self.saveSlot)
        self.btnlcc.clicked.connect(self.lccSlot)
        self.btngrass.clicked.connect(self.grassSlot)
        self.btnany.clicked.connect(self.inforSlot)
        self.btnanygamma.clicked.connect(self.inforSlotgamma)
        self.btnanyblur.clicked.connect(self.inforSlotblur)
        self.btnanylcc.clicked.connect(self.inforSlotlcc)
        self.btnanygrass.clicked.connect(self.inforSlotgrass)
        self.btnanyprocess.clicked.connect(self.inforSlotany)

    def closeEvent(self, event):
        reply = QMessageBox.question(self, '詢問', '請問是否確定返回首頁？',QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
        if reply == QMessageBox.Yes:
            event.accept()
        else:
            event.ignore()

    def openSlot(self):
        self.resize(900,600)
        filename, _ = QFileDialog.getOpenFileName(self, '選取影像', 'Image', '*.png *.jpg *.bmp')
        if filename is '':
            return
        self.label.img = cv2.imread(filename, -1)
        if self.label.img.size == 1:
            return
        self.label.img = cv2.resize(self.label.img,(900,600))
        self.label.showImage(self.label.img)
        height, width, _ = self.label.img.shape
        self.label.setFixedSize(width, height)
        self.btnSave.setEnabled(True)


    def showImage(self):
        height, width = self.label.img.shape[:2][::-1]
        bytesPerline = 3 * width
        self.qImg = QImage(self.label.img.data, width, height, bytesPerline, QImage.Format_RGB888).rgbSwapped()
        self.label.setPixmap(QPixmap.fromImage(self.qImg))



    def saveSlot(self):
        filename, _ = QFileDialog.getSaveFileName(self, '影像分析', 'Image', '*.png *.jpg *.bmp')
        self.label.showImage(self.label.img)
        height, width, _ = self.label.img.shape
        self.label.setFixedSize(width, height)
        if filename is '':
            return
        cv2.imwrite(filename, self.label.img)


    def gammaSlot(self):
        self.label.setPixmap(QPixmap('./lcc_pic/kmeans/gamma_c.jpg'))

    def blurSlot(self):
        self.label.setPixmap(QPixmap('./lcc_pic/kmeans/blur.jpg'))

    def lccSlot(self):
        self.label.setPixmap(QPixmap('./lcc_pic/kmeans/result_p.jpg'))

    def grassSlot(self):
        self.label.setPixmap(QPixmap('./lcc_pic/kmeans/grass.jpg'))

    def processSlot(self):
        cv2.imwrite('./lcc_pic/kmeans/clone.jpg',self.label.img)
        img_s = self.label.img.copy()
        b, g, r = cv2.split(img_s)
        y = .299*r + .587*g + .114*b
        u = -.14713*r -.28886*g + .436*b
        v = .615*r -.51499*g -.10001*b
        y_max = np.max(y)
        y_min = np.min(y)

        y =(((y - y_min)/(y_max - y_min))*255)
        cv2.imwrite('./lcc_pic/kmeans/y.jpg',y)
        image = cv2.imread('./lcc_pic/kmeans/y.jpg')
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        mean = np.mean(gray)
        gamma_val = math.log10(1/2)/math.log10(mean/255)
        img_gammac = gamma_correction(image, gamma_val)
        cv2.imwrite('./lcc_pic/kmeans/gamma_c.jpg',img_gammac)
        k_size = 25
        blur = cv2.GaussianBlur(img_gammac,(k_size,k_size),0)
        cv2.imwrite('./lcc_pic/kmeans/blur.jpg',blur)
        result_p, mask = hsv_w_turn(img_s,blur)
        seg_bgr, seg_num = keep_g(result_p)
        seg_bgr1 = list(reversed(seg_bgr))
        seg_num1 = list(reversed(seg_num))
        #print("顏色淺到深編號：:", seg_num1)
        seg_num2 = seg_num1.copy()

        kernel_1 = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))
        dilate = cv2.dilate(mask, kernel_1, iterations = 3)
        grass, gmask = find_grass(img_s, blur, dilate)
        cv2.imwrite('./lcc_pic/kmeans/gmask.jpg',gmask)
        bgr_center = rmbg(grass)

        dist = []
        for i in range(len(seg_bgr1)):
            dist.append(ColourDistance(seg_bgr1[i], bgr_center))

        for m in range(len(dist)):
            for n in range(len(dist) - 1):
                if dist[n] > dist[n+1]:
                    dist[n], dist[n+1] = dist[n+1], dist[n]
                    seg_num1[n], seg_num1[n+1] = seg_num1[n+1], seg_num1[n]

        #print("距離排序編號",seg_num1)
        corr0_num = int(seg_num2.index(seg_num1[0]))
        print(corr0_num)
        corr_num = str(corr0_num + 1)
        self.label1.setText("最接近色塊："+corr_num+" 號")


    def inforSlot(self):
        QMessageBox.information(self, '使用說明','點選您欲輸入的照片，再點選開啟，將照片輸入至系統中。',QMessageBox.Yes|QMessageBox.No,QMessageBox.Yes) 
    
    def inforSlotgamma(self):
        QMessageBox.information(self, '使用說明',' 此步驟將您的照片拉開對比。',QMessageBox.Yes|QMessageBox.No,QMessageBox.Yes) 

    def inforSlotblur(self):
        QMessageBox.information(self, '使用說明','在提取遮罩前記得先去除雜訊喔！利用模糊影像就可以避免雜訊的影響！',QMessageBox.Yes|QMessageBox.No,QMessageBox.Yes) 

    def inforSlotlcc(self):
        QMessageBox.information(self, '使用說明','此步驟能提取葉色板的遮罩，跟原影像結合後就能找到葉色板。',QMessageBox.Yes|QMessageBox.No,QMessageBox.Yes) 

    def inforSlotgrass(self):
        QMessageBox.information(self, '使用說明','排除葉色板的部分並提取綠色的範圍，即可找到葉子！',QMessageBox.Yes|QMessageBox.No,QMessageBox.Yes) 

    def inforSlotany(self):
        QMessageBox.information(self, '使用說明','將葉子顏色透過Kmeans計算葉色平均，再跟每塊葉色塊的顏色平均比對，找出最相近的葉色塊。',QMessageBox.Yes|QMessageBox.No,QMessageBox.Yes) 



if __name__ == '__main__':
     app = QApplication(sys.argv)
     window = Ui_MainWindow()
     secwindow = MyDialog()
     thriwindow = MyDialog2()


     window.show()
     window.pushButton.clicked.connect(secwindow.show)
     window.pushButton_2.clicked.connect(thriwindow.show)


     sys.exit(app.exec_())